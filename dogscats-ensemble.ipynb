{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available  (error: Unable to get the number of gpus available: unknown error)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/fast-ai/data/dogscats\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir+'/data/dogscats'\n",
    "\n",
    "%cd $DATA_HOME_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/ubuntu/fast-ai/data/dogscats'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"./\"\n",
    "model_path = path + 'models/'\n",
    "\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path+'train', shuffle=False, batch_size=batch_size)\n",
    "val_batches = get_batches(path+'valid', shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 0 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we're going to create an ensemble of models and use their average as our predictions. For each ensemble, we're going to follow our usual fine-tuning steps:\n",
    "\n",
    "1) Create a model that retrains just the last layer\n",
    "2) Add this to a model containing all VGG layers except the last layer\n",
    "3) Fine-tune just the dense layers of this model (pre-computing the convolutional layers)\n",
    "4) Add data augmentation, fine-tuning the dense layers without pre-computation.\n",
    "\n",
    "So first, we need to create our VGG model and pre-compute the output of the conv layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import vgg16\n",
    "\n",
    "model = vgg16.VGG16(weights = 'imagenet', include_top=True)\n",
    "conv_layers,fc_layers = split_at(model, Convolution2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_features = conv_model.predict_generator(val_batches, val_batches.nb_sample)\n",
    "trn_features = conv_model.predict_generator(batches, batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(model_path + 'train_convlayer_features.bc', trn_features)\n",
    "save_array(model_path + 'valid_convlayer_features.bc', val_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future we can just load these precomputed features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_features = load_array(model_path+'train_convlayer_features.bc')\n",
    "val_features = load_array(model_path+'valid_convlayer_features.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can precompute the output of all but the last dropout and dense layers, for creating the first stage of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x7f802e0b0950>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers.pop()\n",
    "model.layers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model = Sequential()\n",
    "fc_model.add(MaxPooling2D(input_shape=(512,14,14)))\n",
    "fc_model.add(Flatten())\n",
    "fc_model.add(Dense(4096, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 512, 7, 7)     0           maxpooling2d_input_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 25088)         0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096)          102764544   flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 102,764,544\n",
      "Trainable params: 102,764,544\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for l1,l2 in zip(fc_model.layers, model.layers[-3:]): \n",
    "    weights = l2.get_weights()\n",
    "    l1.set_weights(weights)\n",
    "fc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', \n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ll_val_feat = fc_model.predict(val_features)\n",
    "ll_feat = fc_model.predict(trn_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(model_path + 'train_ll_feat.bc', ll_feat)\n",
    "save_array(model_path + 'valid_ll_feat.bc', ll_val_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ll_feat = load_array(model_path+ 'train_ll_feat.bc')\n",
    "ll_val_feat = load_array(model_path + 'valid_ll_feat.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batches = get_batches(path+'test',shuffle=False, batch_size=batch_size)\n",
    "test_features = conv_model.predict_generator(test_batches, test_batches.n)\n",
    "save_array(model_path + 'test_convlayer_features.bc', val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_feature = load_array(model_path+'train_convlayer_features.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions automate creating a model that trains the last layer from scratch, and then adds those new layers on to the main model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ll_layers():\n",
    "    return [ \n",
    "        BatchNormalization(input_shape=(4096,)),\n",
    "        Dropout(0.5),\n",
    "        Dense(2, activation='softmax') \n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_last_layer(i):\n",
    "    ll_layers = get_ll_layers()\n",
    "    ll_model = Sequential(ll_layers)\n",
    "    ll_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    ll_model.optimizer.lr=1e-5\n",
    "    ll_model.fit(ll_feat, trn_labels, validation_data=(ll_val_feat, val_labels), nb_epoch=12)\n",
    "    ll_model.optimizer.lr=1e-7\n",
    "    ll_model.fit(ll_feat, trn_labels, validation_data=(ll_val_feat, val_labels), nb_epoch=1)\n",
    "    ll_model.save_weights(model_path+'ll_bn' + i + '.h5')\n",
    "\n",
    "    vgg = vgg16.VGG16(weights='imagenet', include_top=True)\n",
    "    vgg.layers.pop(); vgg.layers.pop(); \n",
    "    #vgg.layers.pop()\n",
    "    model = Sequential(vgg.layers)\n",
    "    \n",
    "    for layer in model.layers: layer.trainable=False\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    ll_layers = get_ll_layers()\n",
    "    for layer in ll_layers: model.add(layer)\n",
    "    for l1,l2 in zip(ll_model.layers, model.layers[-3:]):\n",
    "        l2.set_weights(l1.get_weights())\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.save_weights(model_path+'bn' + i + '.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_conv_model(model):\n",
    "    layers = model.layers\n",
    "    last_conv_idx = [index for index,layer in enumerate(layers) \n",
    "                         if type(layer) is Convolution2D][-1]\n",
    "\n",
    "    conv_layers = layers[:last_conv_idx+1]\n",
    "    conv_model = Sequential(conv_layers)\n",
    "    fc_layers = layers[last_conv_idx+1:]\n",
    "    return conv_model, fc_layers, last_conv_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_layers(p, in_shape):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=in_shape),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(2, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_dense_layers(i, model):\n",
    "    conv_model, fc_layers, last_conv_idx = get_conv_model(model)\n",
    "    conv_shape = conv_model.output_shape[1:]\n",
    "    fc_model = Sequential(get_fc_layers(0.5, conv_shape))\n",
    "    for l1,l2 in zip(fc_model.layers[-3:], fc_layers[-3:]): \n",
    "        weights = l2.get_weights()\n",
    "        l1.set_weights(weights)\n",
    "    fc_model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', \n",
    "                     metrics=['accuracy'])\n",
    "    fc_model.fit(trn_features, trn_labels, nb_epoch=4, \n",
    "         batch_size=batch_size, validation_data=(val_features, val_labels))\n",
    "\n",
    "#     gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=0.05, \n",
    "#        width_zoom_range=0.05, zoom_range=0.05,\n",
    "#        channel_shift_range=10, height_shift_range=0.05, shear_range=0.05, horizontal_flip=True)\n",
    "#     batches = gen.flow(trn, trn_labels, batch_size=batch_size)\n",
    "#     val_batches = image.ImageDataGenerator().flow(val, val_labels, batch_size=batch_size)\n",
    "\n",
    "    for layer in conv_model.layers: layer.trainable = False\n",
    "    for layer in get_fc_layers(0.5, conv_shape): conv_model.add(layer)\n",
    "    for l1,l2 in zip(conv_model.layers[last_conv_idx+1:], fc_model.layers): \n",
    "        l1.set_weights(l2.get_weights())\n",
    "\n",
    "    conv_model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', \n",
    "                       metrics=['accuracy'])\n",
    "    conv_model.save_weights(model_path+'no_dropout_bn' + i + '.h5')\n",
    "    return conv_model \n",
    "#     conv_model.fit_generator(batches, samples_per_epoch=batches.n, nb_epoch=1, \n",
    "#                             validation_data=val_batches, nb_val_samples=val_batches.n)\n",
    "#     \n",
    "#     for layer in conv_model.layers[16:]: layer.trainable = True\n",
    "#     conv_model.fit_generator(batches, samples_per_epoch=batches.n, nb_epoch=1, \n",
    "#                             validation_data=val_batches, nb_val_samples=val_batches.n)\n",
    "\n",
    "#     conv_model.optimizer.lr = 1e-7\n",
    "#     conv_model.fit_generator(batches, samples_per_epoch=batches.n, nb_epoch=1, \n",
    "#                             validation_data=val_batches, nb_val_samples=val_batches.n)\n",
    "#     conv_model.save_weights(model_path + 'aug' + i + '.h5')\n",
    "#     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Build ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.6291 - acc: 0.7395 - val_loss: 0.2533 - val_acc: 0.8930\n",
      "Epoch 2/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.3295 - acc: 0.8722 - val_loss: 0.1768 - val_acc: 0.9325\n",
      "Epoch 3/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.2573 - acc: 0.8996 - val_loss: 0.1467 - val_acc: 0.9440\n",
      "Epoch 4/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.2255 - acc: 0.9142 - val_loss: 0.1279 - val_acc: 0.9495\n",
      "Epoch 5/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1972 - acc: 0.9266 - val_loss: 0.1186 - val_acc: 0.9525\n",
      "Epoch 6/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1831 - acc: 0.9300 - val_loss: 0.1123 - val_acc: 0.9565\n",
      "Epoch 7/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1767 - acc: 0.9366 - val_loss: 0.1057 - val_acc: 0.9590\n",
      "Epoch 8/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1692 - acc: 0.9385 - val_loss: 0.1026 - val_acc: 0.9600\n",
      "Epoch 9/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1582 - acc: 0.9441 - val_loss: 0.0994 - val_acc: 0.9635\n",
      "Epoch 10/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1486 - acc: 0.9465 - val_loss: 0.0973 - val_acc: 0.9635\n",
      "Epoch 11/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1527 - acc: 0.9451 - val_loss: 0.0960 - val_acc: 0.9625\n",
      "Epoch 12/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1491 - acc: 0.9470 - val_loss: 0.0936 - val_acc: 0.9625\n",
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "23000/23000 [==============================] - 7s - loss: 0.1433 - acc: 0.9481 - val_loss: 0.0915 - val_acc: 0.9645\n",
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/4\n",
      "23000/23000 [==============================] - 367s - loss: 0.2032 - acc: 0.9200 - val_loss: 0.1104 - val_acc: 0.9550\n",
      "Epoch 2/4\n",
      "23000/23000 [==============================] - 366s - loss: 0.0925 - acc: 0.9658 - val_loss: 0.0900 - val_acc: 0.9650\n",
      "Epoch 3/4\n",
      "23000/23000 [==============================] - 365s - loss: 0.0587 - acc: 0.9777 - val_loss: 0.0862 - val_acc: 0.9705\n",
      "Epoch 4/4\n",
      "23000/23000 [==============================] - 368s - loss: 0.0415 - acc: 0.9839 - val_loss: 0.0884 - val_acc: 0.9690\n",
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.6891 - acc: 0.7186 - val_loss: 0.2755 - val_acc: 0.8920\n",
      "Epoch 2/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.3559 - acc: 0.8598 - val_loss: 0.1891 - val_acc: 0.9240\n",
      "Epoch 3/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.2783 - acc: 0.8940 - val_loss: 0.1552 - val_acc: 0.9405\n",
      "Epoch 4/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.2377 - acc: 0.9103 - val_loss: 0.1403 - val_acc: 0.9460\n",
      "Epoch 5/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.2150 - acc: 0.9199 - val_loss: 0.1293 - val_acc: 0.9500\n",
      "Epoch 6/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1986 - acc: 0.9280 - val_loss: 0.1204 - val_acc: 0.9525\n",
      "Epoch 7/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1887 - acc: 0.9317 - val_loss: 0.1179 - val_acc: 0.9545\n",
      "Epoch 8/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1770 - acc: 0.9350 - val_loss: 0.1142 - val_acc: 0.9540\n",
      "Epoch 9/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1772 - acc: 0.9383 - val_loss: 0.1108 - val_acc: 0.9555\n",
      "Epoch 10/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1646 - acc: 0.9410 - val_loss: 0.1091 - val_acc: 0.9575\n",
      "Epoch 11/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1574 - acc: 0.9435 - val_loss: 0.1070 - val_acc: 0.9575\n",
      "Epoch 12/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1540 - acc: 0.9443 - val_loss: 0.1052 - val_acc: 0.9600\n",
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "23000/23000 [==============================] - 7s - loss: 0.1536 - acc: 0.9450 - val_loss: 0.1013 - val_acc: 0.9610\n",
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/4\n",
      "23000/23000 [==============================] - 365s - loss: 0.2092 - acc: 0.9192 - val_loss: 0.1136 - val_acc: 0.9545\n",
      "Epoch 2/4\n",
      "23000/23000 [==============================] - 366s - loss: 0.0892 - acc: 0.9657 - val_loss: 0.0955 - val_acc: 0.9620\n",
      "Epoch 3/4\n",
      "23000/23000 [==============================] - 366s - loss: 0.0620 - acc: 0.9760 - val_loss: 0.1016 - val_acc: 0.9625\n",
      "Epoch 4/4\n",
      "23000/23000 [==============================] - 367s - loss: 0.0386 - acc: 0.9861 - val_loss: 0.0945 - val_acc: 0.9665\n",
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.6622 - acc: 0.7266 - val_loss: 0.2734 - val_acc: 0.8910\n",
      "Epoch 2/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.3580 - acc: 0.8595 - val_loss: 0.1857 - val_acc: 0.9285\n",
      "Epoch 3/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.2758 - acc: 0.8955 - val_loss: 0.1508 - val_acc: 0.9415\n",
      "Epoch 4/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.2364 - acc: 0.9101 - val_loss: 0.1319 - val_acc: 0.9490\n",
      "Epoch 5/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.2120 - acc: 0.9212 - val_loss: 0.1214 - val_acc: 0.9520\n",
      "Epoch 6/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1908 - acc: 0.9285 - val_loss: 0.1127 - val_acc: 0.9545\n",
      "Epoch 7/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1856 - acc: 0.9330 - val_loss: 0.1082 - val_acc: 0.9570\n",
      "Epoch 8/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1734 - acc: 0.9357 - val_loss: 0.1044 - val_acc: 0.9570\n",
      "Epoch 9/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1675 - acc: 0.9376 - val_loss: 0.1048 - val_acc: 0.9590\n",
      "Epoch 10/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1595 - acc: 0.9417 - val_loss: 0.0993 - val_acc: 0.9615\n",
      "Epoch 11/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1503 - acc: 0.9450 - val_loss: 0.0978 - val_acc: 0.9605\n",
      "Epoch 12/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1507 - acc: 0.9474 - val_loss: 0.0960 - val_acc: 0.9615\n",
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "23000/23000 [==============================] - 7s - loss: 0.1524 - acc: 0.9459 - val_loss: 0.0959 - val_acc: 0.9630\n",
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/4\n",
      "23000/23000 [==============================] - 365s - loss: 0.2119 - acc: 0.9177 - val_loss: 0.1001 - val_acc: 0.9565\n",
      "Epoch 2/4\n",
      "23000/23000 [==============================] - 366s - loss: 0.0900 - acc: 0.9653 - val_loss: 0.0946 - val_acc: 0.9645\n",
      "Epoch 3/4\n",
      "23000/23000 [==============================] - 366s - loss: 0.0534 - acc: 0.9790 - val_loss: 0.0931 - val_acc: 0.9655\n",
      "Epoch 4/4\n",
      "23000/23000 [==============================] - 366s - loss: 0.0380 - acc: 0.9858 - val_loss: 0.0935 - val_acc: 0.9650\n",
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.7474 - acc: 0.7045 - val_loss: 0.3121 - val_acc: 0.8735\n",
      "Epoch 2/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.3760 - acc: 0.8521 - val_loss: 0.2109 - val_acc: 0.9190\n",
      "Epoch 3/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.2787 - acc: 0.8934 - val_loss: 0.1746 - val_acc: 0.9365\n",
      "Epoch 4/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.2347 - acc: 0.9117 - val_loss: 0.1552 - val_acc: 0.9420\n",
      "Epoch 5/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.2115 - acc: 0.9222 - val_loss: 0.1420 - val_acc: 0.9480\n",
      "Epoch 6/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.2022 - acc: 0.9270 - val_loss: 0.1344 - val_acc: 0.9515\n",
      "Epoch 7/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1916 - acc: 0.9326 - val_loss: 0.1266 - val_acc: 0.9540\n",
      "Epoch 8/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1756 - acc: 0.9352 - val_loss: 0.1228 - val_acc: 0.9565\n",
      "Epoch 9/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1750 - acc: 0.9383 - val_loss: 0.1181 - val_acc: 0.9565\n",
      "Epoch 10/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23000/23000 [==============================] - 7s - loss: 0.1658 - acc: 0.9409 - val_loss: 0.1153 - val_acc: 0.9605\n",
      "Epoch 11/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1596 - acc: 0.9444 - val_loss: 0.1111 - val_acc: 0.9615\n",
      "Epoch 12/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1501 - acc: 0.9458 - val_loss: 0.1121 - val_acc: 0.9605\n",
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "23000/23000 [==============================] - 7s - loss: 0.1474 - acc: 0.9471 - val_loss: 0.1081 - val_acc: 0.9625\n",
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/4\n",
      "23000/23000 [==============================] - 365s - loss: 0.2062 - acc: 0.9185 - val_loss: 0.0981 - val_acc: 0.9620\n",
      "Epoch 2/4\n",
      "23000/23000 [==============================] - 367s - loss: 0.0901 - acc: 0.9656 - val_loss: 0.0895 - val_acc: 0.9670\n",
      "Epoch 3/4\n",
      "23000/23000 [==============================] - 367s - loss: 0.0578 - acc: 0.9774 - val_loss: 0.0863 - val_acc: 0.9690\n",
      "Epoch 4/4\n",
      "23000/23000 [==============================] - 366s - loss: 0.0415 - acc: 0.9846 - val_loss: 0.0903 - val_acc: 0.9685\n",
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.7978 - acc: 0.6805 - val_loss: 0.3387 - val_acc: 0.8530\n",
      "Epoch 2/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.3799 - acc: 0.8503 - val_loss: 0.2274 - val_acc: 0.9100\n",
      "Epoch 3/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.2769 - acc: 0.8927 - val_loss: 0.1894 - val_acc: 0.9300\n",
      "Epoch 4/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.2418 - acc: 0.9087 - val_loss: 0.1656 - val_acc: 0.9365\n",
      "Epoch 5/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.2205 - acc: 0.9199 - val_loss: 0.1537 - val_acc: 0.9470\n",
      "Epoch 6/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1996 - acc: 0.9259 - val_loss: 0.1449 - val_acc: 0.9490\n",
      "Epoch 7/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1846 - acc: 0.9318 - val_loss: 0.1389 - val_acc: 0.9500\n",
      "Epoch 8/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1698 - acc: 0.9376 - val_loss: 0.1335 - val_acc: 0.9540\n",
      "Epoch 9/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1744 - acc: 0.9380 - val_loss: 0.1301 - val_acc: 0.9565\n",
      "Epoch 10/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1638 - acc: 0.9408 - val_loss: 0.1259 - val_acc: 0.9570\n",
      "Epoch 11/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1607 - acc: 0.9416 - val_loss: 0.1218 - val_acc: 0.9575\n",
      "Epoch 12/12\n",
      "23000/23000 [==============================] - 7s - loss: 0.1567 - acc: 0.9433 - val_loss: 0.1224 - val_acc: 0.9590\n",
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "23000/23000 [==============================] - 7s - loss: 0.1525 - acc: 0.9457 - val_loss: 0.1200 - val_acc: 0.9580\n",
      "Train on 23000 samples, validate on 2000 samples\n",
      "Epoch 1/4\n",
      "23000/23000 [==============================] - 366s - loss: 0.2065 - acc: 0.9210 - val_loss: 0.1026 - val_acc: 0.9570\n",
      "Epoch 2/4\n",
      "23000/23000 [==============================] - 366s - loss: 0.0924 - acc: 0.9658 - val_loss: 0.0897 - val_acc: 0.9660\n",
      "Epoch 3/4\n",
      "23000/23000 [==============================] - 366s - loss: 0.0590 - acc: 0.9767 - val_loss: 0.0962 - val_acc: 0.9640\n",
      "Epoch 4/4\n",
      "23000/23000 [==============================] - 366s - loss: 0.0411 - acc: 0.9840 - val_loss: 0.0857 - val_acc: 0.9695\n"
     ]
    }
   ],
   "source": [
    "ens_pred = []\n",
    "for i in range(5):\n",
    "    i = str(i)\n",
    "    model = train_last_layer(i)\n",
    "    ens_model = train_dense_layers(i, model)\n",
    "    pred = ens_model.predict_generator(path+'valid',shuffle=False, batch_size=batch_size)\n",
    "    ens_pred.append(pred)\n",
    "    \n",
    "val_avg_preds = np.stack(ens_pred).mean(axis=0)\n",
    "categorical_accuracy(val_labels, val_avg_preds).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine ensemble and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get model then set weights\n",
    "vgg = vgg16.VGG16(weights='imagenet', include_top=True)\n",
    "ens_model = Sequential(vgg.layers[:-5])\n",
    "for layer in get_fc_layers(0.5, ens_model.output_shape[1:]): ens_model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ens_model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fc_pred(val_features):\n",
    "    fc_model = Sequential()\n",
    "    for layer in get_fc_layers(0.5, (512,14,14)):\n",
    "        fc_model.add(layer)\n",
    "\n",
    "    fc_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    preds = []\n",
    "    for i in range(5):\n",
    "        ens_model.load_weights('models/no_dropout_bn' + str(i) +'.h5')\n",
    "        for l2,l1 in zip(ens_model.layers[-9:], fc_model.layers): \n",
    "            l1.set_weights(l2.get_weights())\n",
    "        pred = fc_model.predict(val_features)\n",
    "        preds.append(pred)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_avg_preds = np.stack(get_fc_pred).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.9704999923706055, dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_accuracy(val_labels, val_avg_preds).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ens_pred(arr, fname):\n",
    "    ens_pred = []\n",
    "    for i in range(5):\n",
    "        i = str(i)\n",
    "        ens_model.load_weights('{}{}{}.h5'.format(model_path, fname, i))\n",
    "        preds = ens_model.predict_generator(arr,arr.n)\n",
    "        ens_pred.append(preds)\n",
    "    return ens_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg/keras/engine/training.py\", line 433, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg/keras/preprocessing/image.py\", line 822, in next\n",
      "    index_array, current_index, current_batch_size = next(self.index_generator)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg/keras/preprocessing/image.py\", line 645, in _flow_index\n",
      "    current_index = (self.batch_index * batch_size) % n\n",
      "ZeroDivisionError: integer division or modulo by zero\n",
      "\n",
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg/keras/engine/training.py\", line 433, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg/keras/preprocessing/image.py\", line 822, in next\n",
      "    index_array, current_index, current_batch_size = next(self.index_generator)\n",
      "StopIteration\n",
      "\n",
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg/keras/engine/training.py\", line 433, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg/keras/preprocessing/image.py\", line 822, in next\n",
      "    index_array, current_index, current_batch_size = next(self.index_generator)\n",
      "StopIteration\n",
      "\n",
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg/keras/engine/training.py\", line 433, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg/keras/preprocessing/image.py\", line 822, in next\n",
      "    index_array, current_index, current_batch_size = next(self.index_generator)\n",
      "StopIteration\n",
      "\n",
      "Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg/keras/engine/training.py\", line 433, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg/keras/preprocessing/image.py\", line 822, in next\n",
      "    index_array, current_index, current_batch_size = next(self.index_generator)\n",
      "StopIteration\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_pred = get_ens_pred(val_batches, 'no_dropout_bn')\n",
    "test_pred = get_ens_pred(test_batches, 'no_dropout_bn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_avg_preds = np.stack(val_pred).mean(axis=0)\n",
    "test_avg_preds = np.stack(test_pred).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.8740000128746033, dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_accuracy(val_labels, val_avg_preds).eval()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
